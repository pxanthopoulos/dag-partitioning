import subprocess
import sys
import argparse
import os
from tqdm import tqdm

def print_summary(iterations_run, total_planned, current_failures, baseline_failures, interrupted=False):
    """Print test execution summary"""
    status = "INTERRUPTED" if interrupted else "COMPLETED"
    print(f"\n=== Test Summary ({status}) ===")
    print(f"Iterations run: {iterations_run} / {total_planned}")
    if interrupted:
        print(f"Progress: {(iterations_run / total_planned * 100):.1f}% complete when interrupted")
    print(f"Current implementation failures: {current_failures}")
    print(f"Baseline implementation failures: {baseline_failures}")
    
    if iterations_run > 0:
        print(f"Success rate - Current: {((iterations_run - current_failures) / iterations_run * 100):.1f}%")
        print(f"Success rate - Baseline: {((iterations_run - baseline_failures) / iterations_run * 100):.1f}%")
    else:
        print("No iterations completed.")

def cleanup_files(args, dag_dot_path, node_mappings_current, node_mappings_dagp):
    """Clean up generated files"""
    cleanup_files_list = [dag_dot_path, node_mappings_current, node_mappings_dagp]
    if not args.keep_subprocess_log:
        cleanup_files_list.append(args.subprocess_log)
    
    for file_path in cleanup_files_list:
        try:
            if os.path.exists(file_path):
                os.remove(file_path)
                print(f"Cleaned up: {file_path}")
        except OSError as e:
            print(f"Warning: Could not remove {file_path}: {e}")

def validate_ratios(ratios_str):
    """Parse and validate ratios from comma-separated string"""
    try:
        ratios = [int(x.strip()) for x in ratios_str.split(',')]
        for ratio in ratios:
            if ratio < 100:
                raise argparse.ArgumentTypeError(f"Ratio {ratio} must be >= 100")
        return ratios
    except ValueError:
        raise argparse.ArgumentTypeError(f"Ratios must be comma-separated integers: {ratios_str}")

def validate_sizes(sizes_str):
    """Parse and validate sizes from comma-separated string"""
    try:
        sizes = [int(x.strip()) for x in sizes_str.split(',')]
        for size in sizes:
            if size <= 0:
                raise argparse.ArgumentTypeError(f"Size {size} must be a positive integer")
        return sizes
    except ValueError:
        raise argparse.ArgumentTypeError(f"Sizes must be comma-separated positive integers: {sizes_str}")

def validate_timeout(timeout_str):
    """Parse and validate timeout duration string"""
    import re
    
    # Match floating point number with optional suffix
    pattern = r'^(\d*\.?\d+)([smhd]?)$'
    match = re.match(pattern, timeout_str.strip())
    
    if not match:
        raise argparse.ArgumentTypeError(f"Invalid timeout format: {timeout_str}. Expected format: number[smhd]")
    
    value, suffix = match.groups()
    try:
        value = float(value)
        if value < 0:
            raise argparse.ArgumentTypeError(f"Timeout value must be non-negative: {value}")
    except ValueError:
        raise argparse.ArgumentTypeError(f"Invalid timeout value: {value}")
    
    # Validate suffix (s=seconds, m=minutes, h=hours, d=days)
    if suffix and suffix not in 'smhd':
        raise argparse.ArgumentTypeError(f"Invalid timeout suffix: {suffix}. Valid suffixes: s, m, h, d")
    
    return timeout_str.strip()  # Return original format for timeout command

def parse_args():
    parser = argparse.ArgumentParser(description='Compare dag-partitioning implementations')
    parser.add_argument('--current-trace-file', default='./trace-current.txt', 
                       help='Output trace file for current implementation (default: ./trace-current.txt)')
    parser.add_argument('--baseline-trace-file', default='./trace-dagp.txt',
                       help='Output trace file for baseline (dagp) implementation (default: ./trace-dagp.txt)')
    parser.add_argument('--dag-output-file', default='./dag.dot',
                       help='Temporary DAG file generated by rand-dag (default: ./dag.dot)')
    parser.add_argument('--subprocess-log', default='./subprocesses.log',
                       help='Log file for subprocess errors (default: ./subprocesses.log)')
    parser.add_argument('--keep-subprocess-log', action='store_true',
                       help='Keep subprocess log file after execution (default: remove it)')
    parser.add_argument('--ratios', type=validate_ratios, default='100,150,200,250,300,500',
                       help='Comma-separated ratios (integers >= 100) (default: 100,150,200,250,300,500)')
    parser.add_argument('--sizes', type=validate_sizes, default='20,50,100,150,200,500,1000,2000,5000,10000,50000',
                       help='Comma-separated sizes (positive integers) (default: 20,50,100,150,200,500,1000,2000,5000,10000,50000)')
    parser.add_argument('--timeout', type=validate_timeout, default='5m',
                       help='Timeout duration for each test (format: number[smhd], e.g., 5m, 30s, 1h) (default: 5m)')
    parser.add_argument('--runs', type=int, default=5,
                       help='Number of runs per partition configuration (default: 5)')
    parser.add_argument('--max-base-partitions', type=int, default=5,
                       help='Maximum value for base partition range (2 to this value inclusive). Power-of-2 sequence starts from next power of 2 after this limit (default: 5)')
    parser.add_argument('--baseline-executable', required=True,
                       help='Path to baseline (dagp) executable for comparison')
    return parser.parse_args()

def calculate_partitions(size, max_base=5):
    partitions = []
    
    # Add base partitions from 2 to max_base (inclusive)
    for i in range(2, max_base + 1):
        partitions.append(i)
    
    # Find next power of 2 after max_base
    power = 1
    while power <= max_base:
        power *= 2
    
    # Add power-of-2 partitions starting from the next power of 2 after max_base
    sizediv2 = size // 2
    while power <= sizediv2:
        partitions.append(power)
        power *= 2
    
    return partitions

def calculate_total_iterations(ratios, sizes, runs, max_base):
    total = 0
    for ratio in ratios:
        for size in sizes:
            partitions = calculate_partitions(size, max_base)
            total += len(partitions) * runs
    return total

def main():
    args = parse_args()
    
    # Get script directory and project root
    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(script_dir)  # Go up one level from test/ to project root
    
    # Paths relative to project root
    rand_dag_path = os.path.join(project_root, 'install', 'bin', 'rand-dag')
    test_executable_path = os.path.join(project_root, 'install', 'bin', 'test')
    dag_dot_path = os.path.abspath(args.dag_output_file)
    
    # Files created by executables that need cleanup
    node_mappings_current = dag_dot_path + '.node-mappings.txt'
    node_mappings_dagp = dag_dot_path + '.nodemappings'
    
    # Clear trace files
    open(args.current_trace_file, 'w').close()
    open(args.baseline_trace_file, 'w').close()
    
    counter = 1
    total_iterations = calculate_total_iterations(args.ratios, args.sizes, args.runs, args.max_base_partitions)
    current_failures = 0
    baseline_failures = 0
    iterations_run = 0
    interrupted = False
    
    # Create progress bar with colors
    pbar = tqdm(total=total_iterations, desc="Tests", 
                bar_format="{desc}: {percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]",
                colour='green')

    try:
        for ratio in args.ratios:
            for size in args.sizes:
                partitions = calculate_partitions(size, args.max_base_partitions)
                
                for p in partitions:
                    for i in range(1, args.runs + 1):
                        pbar.set_description(f"C{counter} R{i} S{size} Ra{ratio} P{p}")
                        pbar.update(1)
                        iterations_run += 1
                        with open(args.current_trace_file, 'a') as f:
                            f.write(f"Counter {counter}, Run {i}, Size {size}, Ratio {ratio}, Partitions {p}\n")
                        with open(args.baseline_trace_file, 'a') as f:
                            f.write(f"Counter {counter}, Run {i}, Size {size}, Ratio {ratio}, Partitions {p}\n")
                        
                        # Run rand-dag
                        try:
                            with open(args.subprocess_log, 'a') as log_f:
                                subprocess.run([rand_dag_path, str(size), str(ratio), '0', dag_dot_path], 
                                            check=True, stderr=log_f)
                        except subprocess.CalledProcessError:
                            print(f"Error: rand-dag failed for size {size}, ratio {ratio} (check {args.subprocess_log})")
                        
                        # Run current implementation with timeout
                        try:
                            with open(args.current_trace_file, 'a') as f, open(args.subprocess_log, 'a') as log_f:
                                subprocess.run(['timeout', '--foreground', args.timeout, test_executable_path, str(p), dag_dot_path, '1'], 
                                            stdout=f, stderr=log_f, check=True)
                        except subprocess.CalledProcessError as e:
                            ret = e.returncode
                            current_failures += 1
                            error_msg = f"Error: current implementation failed for size {size}, ratio {ratio}, partitions {p} on iteration {i}"
                            timeout_msg = "TIMED OUT" if ret == 124 else ""
                            with open(args.subprocess_log, 'a') as log_f:
                                log_f.write(f"{error_msg}\n")
                                if timeout_msg:
                                    log_f.write(f"{timeout_msg}\n")
                        
                        # Run baseline implementation with timeout
                        try:
                            with open(args.baseline_trace_file, 'a') as f, open(args.subprocess_log, 'a') as log_f:
                                subprocess.run(['timeout', '--foreground', args.timeout, args.baseline_executable, dag_dot_path, str(p)], 
                                            stdout=f, stderr=log_f, check=True)
                        except subprocess.CalledProcessError as e:
                            ret = e.returncode
                            baseline_failures += 1
                            error_msg = f"Error: baseline implementation failed for size {size}, ratio {ratio}, partitions {p} on iteration {i}"
                            timeout_msg = "TIMED OUT" if ret == 124 else ""
                            with open(args.subprocess_log, 'a') as log_f:
                                log_f.write(f"{error_msg}\n")
                                if timeout_msg:
                                    log_f.write(f"{timeout_msg}\n")
                    
                    counter += 1
    
    except KeyboardInterrupt:
        interrupted = True
        print("\n\nInterrupted by user (Ctrl+C)")
    
    finally:
        pbar.close()
        
        # Print summary and cleanup
        print_summary(iterations_run, total_iterations, current_failures, baseline_failures, interrupted)
        cleanup_files(args, dag_dot_path, node_mappings_current, node_mappings_dagp)

if __name__ == '__main__':
    main()